# Continuous Control - Unity ML-Agents Reacher Enivronment

## Table of Contents
* Project description
* Goal
* Dependencies
* How to start
* Result

## Project description
In this project, I solved the [Reacher] (https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md#reacher) environment with a single agent. I used DDPG (Deep Deterministic Policy Gradient) algorithm.

## Goal
The agent must get an average score of +30 over 100 consecutive episodes.

## Dependencies
* Python 3.6
* Numpy ("pip install numpy")
* [PyTorch](https://pytorch.org/)
* [Reacher](https://github.com/Unity-Technologies/ml-agents)

## How to start
1. Clone this repo
2. To run this project locally, one must build their own environment.
   Below is the link to create local environment:
   * Linux: [Click Here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/Reacher_Linux.zip)
   * Mac OSX: [Click Here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/one_agent/Reacher.app.zip)
   * Windows (32bit): [Click Here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/one_agent/Reacher_Windows_x86.zip)
   * Windows (64bit): [Click Here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P2/Reacher/one_agent/Reacher_Windows_x86_64.zip)
3. Execute each cells in this notebook. The average score per 100 episodes will be shown after agent training is completed. 

## Result
